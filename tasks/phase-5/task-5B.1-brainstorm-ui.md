# TASK 5B.1: Brainstorm Chat UI (Frontend)
> Phase 5 â€” Brainstorm Wizard | Session B (Frontend) | Depends on: Phase 4

## What to Build
Full-screen conversational chat interface for brainstorming project ideas with AI. Provider selector. Streaming response rendering. Structured data extraction panel.

## The Brainstorm Flow
1. User selects AI provider (dropdown: Anthropic/Google/OpenAI/Ollama)
2. Chat interface: conversational back-and-forth about the project idea
3. AI extracts structured data as conversation progresses (project name, tech stack, features)
4. Extracted data displayed in side panel
5. When ready: "Generate Blueprint" button â†’ triggers diagram generation (Task 5B.2)

## Deliverables
1. `BrainstormWizard.tsx` â€” full-screen wizard layout (replaces workspace when active)
2. `ChatBrainstorm.tsx` â€” chat message list + input, streaming token rendering
3. `StructuredExtract.tsx` â€” side panel showing extracted data (name, stack, features, description)
4. Provider selector dropdown
5. Streaming: tokens appear as they arrive via ai:stream_chunk events
6. Conversation state: messages array in React state (not Zustand â€” ephemeral)

## Files to Create/Modify
```
src/components/wizard/BrainstormWizard.tsx  (new)
src/components/wizard/ChatBrainstorm.tsx    (new)
src/components/wizard/StructuredExtract.tsx (new)
src/App.tsx                                 (route to wizard)
```

## Acceptance Test
Open brainstorm wizard. Select Anthropic. Type project idea â†’ AI responds with streaming tokens. Side panel shows extracted project name + tech stack. Conversation continues naturally.

---
## SPEC REFERENCE (Read all of this carefully)
## 4. App Modes & Screens

### 4.1 Home Screen (Launch)

The first thing the user sees on app open:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚                    [App Logo / Name]                             â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                      â”‚  â”‚                                  â”‚â”‚
â”‚  â”‚   [+ New Project]    â”‚  â”‚   ðŸ“Š Dashboard                   â”‚â”‚
â”‚  â”‚                      â”‚  â”‚                                  â”‚â”‚
â”‚  â”‚   Starts brainstorm  â”‚  â”‚   Total sessions: 47             â”‚â”‚
â”‚  â”‚   wizard             â”‚  â”‚   Total cost: $34.21             â”‚â”‚
â”‚  â”‚                      â”‚  â”‚   Tasks completed: 128           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   Hours saved (est): ~64         â”‚â”‚
â”‚                            â”‚                                  â”‚â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”‚   Recent Projects    â”‚                                      â”‚
â”‚  â”‚                      â”‚                                      â”‚
â”‚  â”‚   ðŸ“ grid-betting        last opened 2h ago                â”‚
â”‚  â”‚   ðŸ“ silver-tracker      last opened 1d ago                â”‚
â”‚  â”‚   ðŸ“ portfolio-site      last opened 3d ago                â”‚
â”‚  â”‚                      â”‚                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **New Project** â†’ enters brainstorm wizard (full-screen)
- **Recent Projects** â†’ opens project directly into workspace with last-used mode
- **Dashboard** â†’ aggregate stats across all past sessions

### 4.2 Brainstorm Wizard (New Projects Only)

Full-screen experience triggered by "New Project":

**Step 1 â€” Conversational Brainstorm**
- Chat interface with the AI (user picks which provider: Anthropic, Google, OpenAI, or local Ollama)
- User describes what they want to build in plain English
- AI asks clarifying questions, refines understanding
- AI extracts structured data from the conversation in real-time:
  - Project name
  - Description
  - Tech stack
  - Core features
  - Target platform
  - Key entities / data models

**Step 2 â€” Blueprint Generation**
AI generates a comprehensive project blueprint consisting of:

| Blueprint Layer | Content | Mermaid Diagram Type |
|----------------|---------|---------------------|
| System Architecture | Components, services, data flow | `flowchart` or `C4Context` |
| File/Folder Structure | Directory tree, key files | `graph TD` (tree layout) |
| Database Schema | Tables, relationships, fields | `erDiagram` |
| API Routes | Endpoints, methods, request/response | `flowchart LR` |
| Deployment | Infrastructure, CI/CD, hosting | `flowchart` |

All rendered as interactive Mermaid diagrams with a live preview panel.

**Step 3 â€” Refinement**
- User can edit any diagram manually (Mermaid code editor + visual preview)
- Can chat with AI to request changes ("add a Redis cache layer", "split the auth into its own microservice")
- Each change re-renders in real-time

**Step 4 â€” Export & Launch**
All five export options:
1. **Markdown doc** â€” full blueprint as a readable document
2. **CLAUDE.md** â€” project context file optimized for AI agents to consume
3. **Gastown convoys** â€” tasks exported directly into Gastown's task queue
4. **Scaffolded directories** â€” actually creates the file/folder structure on disk
5. **Reusable template** â€” save the blueprint for future projects with similar structure

After export â†’ transitions to the main workspace with sessions ready to launch.

### 4.3 Main Workspace (Existing Projects)

The primary working view with all panels:

**Floating Mermaid Panel:**
- Toggleable with hotkey (e.g., `m`)
- Shows the living project blueprint
- Nodes update status as agents complete tasks:
  - â¬œ Not started
  - ðŸ”µ In progress
  - ðŸŸ¢ Complete
  - ðŸ”´ Failed/blocked
- Can add/edit/remove nodes on the fly
- Draggable, resizable, can be pinned or floating

---


## 18. AI Provider Router â€” Detailed Architecture

### 18.1 Provider Trait

```rust
use async_trait::async_trait;
use tokio::sync::mpsc;

#[async_trait]
pub trait AiProvider: Send + Sync {
    /// Provider name for UI display
    fn name(&self) -> &str;

    /// Validate that the API key works
    async fn validate_key(&self, key: &str) -> Result<bool, ProviderError>;

    /// Send a message and get a streaming response.
    /// Returns a receiver that yields chunks as they arrive.
    async fn chat_stream(
        &self,
        messages: &[ChatMessage],
        system_prompt: &str,
        options: ChatOptions,
    ) -> Result<mpsc::UnboundedReceiver<StreamChunk>, ProviderError>;

    /// Send a message and get a complete response (non-streaming).
    /// Used for structured data extraction where we need the full response.
    async fn chat_complete(
        &self,
        messages: &[ChatMessage],
        system_prompt: &str,
        options: ChatOptions,
    ) -> Result<String, ProviderError>;
}

pub struct ChatMessage {
    pub role: Role,          // User, Assistant, System
    pub content: String,
}

pub struct ChatOptions {
    pub model: Option<String>,       // override default model
    pub temperature: Option<f32>,    // 0.0-1.0
    pub max_tokens: Option<usize>,
    pub json_mode: bool,             // request JSON output (for structured extraction)
}

pub enum StreamChunk {
    Text(String),              // content token
    Done { usage: TokenUsage }, // stream complete
    Error(String),             // stream error
}

pub struct TokenUsage {
    pub input_tokens: usize,
    pub output_tokens: usize,
}
```

### 18.2 Provider Implementations

| Provider | Crate / Method | Endpoint | Default Model | Auth Options |
|----------|---------------|----------|---------------|-------------|
| Anthropic | `reqwest` â†’ Messages API | `https://api.anthropic.com/v1/messages` | `claude-sonnet-4-5-20250929` | API key (`x-api-key` header) OR OAuth token (subscription) |
| Google | `reqwest` â†’ Gemini API | `https://generativelanguage.googleapis.com/v1beta/` | `gemini-2.0-flash` | API key (`?key=` param) OR Google OAuth (subscription) |
| OpenAI | `reqwest` â†’ Chat Completions | `https://api.openai.com/v1/chat/completions` | `gpt-4o` | API key (`Authorization: Bearer`) OR OAuth token (subscription) |
| Ollama | `reqwest` â†’ Local REST | `http://localhost:11434/api/chat` | User-selected | None (local) |

All use raw `reqwest` with SSE parsing for streaming. No SDK dependencies â€” keeps the binary small and avoids version lock-in.

### 18.2.1 Dual Auth Strategy

Each provider (except Ollama) supports two auth modes:

**API Key mode:**
- User pastes key in Settings
- Direct per-token billing to user's API account
- Higher rate limits, full model access
- Key stored in `~/.config/synk/settings.json` (plaintext â€” same as Claude Code and other CLI tools)

**Subscription Auth mode (OAuth):**
- User clicks "Sign In" â†’ Synk opens browser to provider's OAuth consent screen
- User authorizes Synk â†’ receives OAuth token
- Uses the user's existing subscription (Claude Pro, Gemini Advanced, ChatGPT Plus)
- Token stored in system keyring via `keyring` crate (Linux: libsecret/GNOME Keyring)
- Token refresh handled automatically; re-auth prompt if refresh fails

**Auth selection logic:**
```rust
async fn get_auth(&self) -> AuthHeader {
    // Prefer OAuth token if available and valid
    if let Some(token) = self.oauth_token() {
        if !token.is_expired() {
            return AuthHeader::Bearer(token.access_token);
        }
        // Try refresh
        if let Ok(refreshed) = self.refresh_token(&token).await {
            return AuthHeader::Bearer(refreshed.access_token);
        }
    }
    // Fall back to API key
    if let Some(key) = self.api_key() {
        return AuthHeader::ApiKey(key);
    }
    AuthHeader::None // will cause a ProviderError on next request
}
```

**Rate limit awareness:** Subscription-based access typically has lower rate limits than API keys. Synk shows a warning in the brainstorm wizard if the user is on subscription auth and sends many rapid requests: "You're using subscription auth â€” responses may be rate-limited. Switch to API key for higher throughput."

### 18.3 Conversation State Management

The brainstorm wizard manages a conversation as a **growing message array** stored in the React component's local state (not Zustand â€” it doesn't need to persist across views):

```typescript
interface BrainstormState {
  provider: 'anthropic' | 'google' | 'openai' | 'ollama';
  messages: ChatMessage[];           // full conversation history
  extractedData: ProjectBlueprint;   // structured data extracted so far
  currentPhase: 'brainstorm' | 'blueprint' | 'refine' | 'export';
  isStreaming: boolean;
  streamBuffer: string;              // current response being streamed
}

interface ProjectBlueprint {
  name: string | null;
  description: string | null;
  techStack: string[];
  features: Feature[];
  entities: Entity[];
  diagrams: {
    architecture: string | null;     // mermaid source
    fileStructure: string | null;
    database: string | null;
    apiRoutes: string | null;
    deployment: string | null;
  };
}
```

### 18.4 Conversation Flow: Brainstorm â†’ Blueprint

**Phase 1: Brainstorm Chat**

Every message to the AI includes a system prompt that instructs it to:
1. Ask clarifying questions about the project
2. Extract structured data and embed it in a `<structured>` XML tag at the end of each response
3. Signal when it has enough information to generate blueprints

```
SYSTEM PROMPT (brainstorm phase):
You are a senior software architect helping plan a new project.
Your job is to understand what the user wants to build through conversation.

Ask focused questions about: tech stack preferences, target users,
core features, data models, scale expectations, deployment target.

After each response, include a <structured> block with any new
information you've extracted. Use this exact JSON schema:
<structured>
{
  "name": "project-name-or-null",
  "description": "one-line-description-or-null",
  "tech_stack": ["react", "node"],
  "features": [{"name": "Auth", "description": "User login/signup"}],
  "entities": [{"name": "User", "fields": ["id", "email", "name"]}],
  "ready_for_blueprint": false
}
</structured>

Set ready_for_blueprint to true ONLY when you have enough information
to generate all 5 diagram types. This typically requires understanding:
- Core features (at least 3)
- Data entities (at least 2)
- Tech stack decisions
- Deployment target
```

Synk's frontend parses the `<structured>` block from each response, merges it with the running `ProjectBlueprint` state, and shows a live "extraction progress" indicator in the sidebar:
- âœ… Project name
- âœ… Tech stack (3 items)
- â¬œ Data models (need more detail)
- âœ… Core features (4 identified)
- â¬œ Deployment target

When `ready_for_blueprint` becomes true, the UI shows a "Generate Blueprint â†’" button.

**Phase 2: Blueprint Generation**

User clicks "Generate Blueprint." Synk sends 5 sequential (not parallel) requests to the AI, one per diagram type. Each uses a specialized system prompt:

```
SYSTEM PROMPT (architecture diagram):
Given the following project specification, generate a Mermaid flowchart
diagram showing the system architecture. Include all major components,
services, databases, external APIs, and data flow between them.

Use `flowchart TD` syntax. Use descriptive node labels. Group related
components with subgraph blocks.

Respond with ONLY valid Mermaid syntax. No markdown fences, no explanation.

PROJECT SPEC:
{serialized ProjectBlueprint as JSON}
```

Similar specialized prompts exist for each of the 5 diagram types (see Section D for exact templates).

**Phase 3: Refinement**

User edits diagrams manually OR chats with AI to request changes. When chatting:
- The current Mermaid source is included in the message as context
- AI returns updated Mermaid source
- Synk live-renders the diff in the preview panel

```
SYSTEM PROMPT (refinement):
The user has a project blueprint with diagrams. They want to modify
a specific diagram. The current Mermaid source is provided below.

Return the COMPLETE updated Mermaid source (not a diff). Respond with
ONLY valid Mermaid syntax.

CURRENT DIAGRAM ({diagram_type}):
{current mermaid source}
```

### 18.5 Streaming Implementation

The Rust backend handles SSE parsing. The frontend gets chunks via Tauri events:

```
Frontend calls: invoke('ai_chat_stream', { provider, messages, systemPrompt })
    â”‚
    â–¼
Rust backend:
    1. Opens HTTP connection with streaming enabled
    2. Parses SSE events (data: {"type": "content_block_delta", ...})
    3. Emits Tauri event 'ai:stream-chunk' for each text delta
    4. Emits Tauri event 'ai:stream-done' with token usage on completion
    5. Emits Tauri event 'ai:stream-error' on failure
    â”‚
    â–¼
Frontend:
    1. Listens for 'ai:stream-chunk' events
    2. Appends to streamBuffer
    3. Renders partial markdown in chat UI
    4. On 'ai:stream-done': parse <structured> block, update extractedData
```

---


## 14. File Structure

```
project-root/
â”œâ”€â”€ src-tauri/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs                    # Tauri entry point
â”‚   â”‚   â”œâ”€â”€ lib.rs                     # Module declarations
â”‚   â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”‚   â”œâ”€â”€ session.rs             # Session CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ git.rs                 # Git/worktree operations
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.rs        # Orchestrator adapter commands
â”‚   â”‚   â”‚   â”œâ”€â”€ review.rs              # Diff/merge/review
â”‚   â”‚   â”‚   â”œâ”€â”€ skills.rs              # Skills discovery/toggle
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp.rs                 # MCP server management
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_provider.rs         # AI provider routing
â”‚   â”‚   â”‚   â””â”€â”€ persistence.rs         # Save/restore state
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ process_pool.rs        # Pre-warmed PTY pool
â”‚   â”‚   â”‚   â”œâ”€â”€ session_manager.rs     # Session lifecycle
â”‚   â”‚   â”‚   â”œâ”€â”€ git_manager.rs         # Worktree & merge ops
â”‚   â”‚   â”‚   â”œâ”€â”€ cost_tracker.rs        # Token/cost parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp_server.rs          # Built-in MCP status server
â”‚   â”‚   â”‚   â”œâ”€â”€ skills_discovery.rs    # Auto-detect skills
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp_discovery.rs       # Auto-detect MCP servers
â”‚   â”‚   â”‚   â””â”€â”€ persistence.rs         # Session state storage
â”‚   â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs                 # Orchestrator trait/interface
â”‚   â”‚   â”‚   â”œâ”€â”€ gastown/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs             # Gastown adapter entry
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cli.rs             # gt/bd CLI executor & output parser
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ file_watcher.rs    # inotify watcher on ~/gt/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reconciler.rs      # State reconciler (files â†’ Synk state)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ setup_wizard.rs    # First-time setup flow
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ types.rs           # Gastown data types (Bead, Convoy, Polecat, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_teams.rs         # Claude Agent Teams adapter
â”‚   â”‚   â”‚   â””â”€â”€ manual.rs              # Manual/no orchestrator
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs                 # AI provider trait
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic.rs           # Claude API
â”‚   â”‚   â”‚   â”œâ”€â”€ google.rs              # Gemini API
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.rs              # OpenAI API
â”‚   â”‚   â”‚   â””â”€â”€ ollama.rs              # Local Ollama
â”‚   â”‚   â””â”€â”€ events.rs                  # Tauri event definitions
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â””â”€â”€ tauri.conf.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx                        # Root component + routing
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ home/
â”‚   â”‚   â”‚   â”œâ”€â”€ HomeScreen.tsx         # Welcome + recent projects
â”‚   â”‚   â”‚   â””â”€â”€ DashboardStats.tsx     # Aggregate stats
â”‚   â”‚   â”œâ”€â”€ wizard/
â”‚   â”‚   â”‚   â”œâ”€â”€ BrainstormWizard.tsx   # Full-screen wizard container
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatBrainstorm.tsx     # Conversational AI chat
â”‚   â”‚   â”‚   â”œâ”€â”€ BlueprintViewer.tsx    # Mermaid diagram display
â”‚   â”‚   â”‚   â”œâ”€â”€ BlueprintEditor.tsx    # Manual Mermaid editing
â”‚   â”‚   â”‚   â”œâ”€â”€ ExportPanel.tsx        # Export options
â”‚   â”‚   â”‚   â””â”€â”€ StructuredExtract.tsx  # Real-time data extraction display
â”‚   â”‚   â”œâ”€â”€ workspace/
â”‚   â”‚   â”‚   â”œâ”€â”€ Workspace.tsx          # Main workspace layout
â”‚   â”‚   â”‚   â”œâ”€â”€ SessionGrid.tsx        # Terminal grid
â”‚   â”‚   â”‚   â”œâ”€â”€ SessionPane.tsx        # Individual terminal pane
â”‚   â”‚   â”‚   â””â”€â”€ CommandBar.tsx         # Central command dispatch
â”‚   â”‚   â”œâ”€â”€ sidebar/
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx            # Sidebar container
â”‚   â”‚   â”‚   â”œâ”€â”€ ProjectSelector.tsx    # Project switching
â”‚   â”‚   â”‚   â”œâ”€â”€ SkillsBrowser.tsx      # Skills toggle list
â”‚   â”‚   â”‚   â”œâ”€â”€ McpManager.tsx         # MCP server toggles
â”‚   â”‚   â”‚   â”œâ”€â”€ SessionConfig.tsx      # Per-session settings
â”‚   â”‚   â”‚   â”œâ”€â”€ OrchestratorControls.tsx # Mode selector + controls
â”‚   â”‚   â”‚   â””â”€â”€ AgentStatusOverview.tsx  # Compact status cards
â”‚   â”‚   â”œâ”€â”€ gastown/
â”‚   â”‚   â”‚   â”œâ”€â”€ GastownSetupWizard.tsx # First-time setup flow
â”‚   â”‚   â”‚   â””â”€â”€ GastownDiagnostics.tsx # gt doctor / health panel
â”‚   â”‚   â”œâ”€â”€ drawer/
â”‚   â”‚   â”‚   â”œâ”€â”€ BottomDrawer.tsx       # Drawer container (draggable panels)
â”‚   â”‚   â”‚   â”œâ”€â”€ CostTracker.tsx        # Token/cost display
â”‚   â”‚   â”‚   â”œâ”€â”€ GitActivityFeed.tsx    # Real-time git events
â”‚   â”‚   â”‚   â”œâ”€â”€ TaskQueue.tsx          # Task board (kanban/list)
â”‚   â”‚   â”‚   â””â”€â”€ ReviewQueue.tsx        # PR-style review list
â”‚   â”‚   â”œâ”€â”€ review/
â”‚   â”‚   â”‚   â”œâ”€â”€ ReviewPanel.tsx        # Full review experience
â”‚   â”‚   â”‚   â”œâ”€â”€ DiffViewer.tsx         # Side-by-side diff
â”‚   â”‚   â”‚   â””â”€â”€ CommentThread.tsx      # Line-level comments
â”‚   â”‚   â”œâ”€â”€ planner/
â”‚   â”‚   â”‚   â””â”€â”€ MermaidFloatingPanel.tsx # Floating project planner
â”‚   â”‚   â””â”€â”€ shared/
â”‚   â”‚       â”œâ”€â”€ KeyboardOverlay.tsx    # Shortcut help
â”‚   â”‚       â””â”€â”€ Settings.tsx           # App settings
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ store.ts                   # Zustand state store
â”‚   â”‚   â”œâ”€â”€ tauri-api.ts               # Tauri invoke wrappers
â”‚   â”‚   â”œâ”€â”€ keybindings.ts             # Vim-style key handler
â”‚   â”‚   â”œâ”€â”€ cost-calculator.ts         # Token cost logic
â”‚   â”‚   â”œâ”€â”€ mermaid-utils.ts           # Mermaid generation helpers
â”‚   â”‚   â””â”€â”€ types.ts                   # TypeScript interfaces
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ globals.css                # Tailwind + CSS variables + theme
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ PROJECT_SPEC.md
```

---


